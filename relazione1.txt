Per questa prima esperienza di laboratorio, abbiamo realizzato un software di classificazione audio, realizzato in Python, che permettesse di analizzare e distinguere un file musicale da uno di parlato.
Per realizzare questo compito abbiamo usufruito di un database di 40 file audio .wav, MONO e con frequenza di campionamento pari a 16000 Hz, già suddivisi in 20 file di musica (dalla durata di 10 s l'uno) e 20 file di parlato (dalla durata di 3 s l'uno). Abbiamo inoltre in dotazione un database di 10 suoni incogniti, sempre MONO a 16000 Hz, che il nostro software dovrà essere in grado di dividere in musica o parlato.
Il primo passo per creare il software di classificazione è la fase di training, attraverso la quale si addestra il software a distinguere musica e parlato facendogli analizzare i 40 file già suddivisi nelle due categorie.
In secondo luogo si attua la fase di test, in cui si consegnano al software i 10 file incogniti, che verranno analizzati dal programma e suddivisi in musica o parlato.

Per raggiungere questi obiettivi, è stato necessario utilizzare le estensioni Scipy e Numpy, che implementano funzioni matematiche di alto livello. In particolare abbiamo utilizzato due funzioni fondamentali: spectrogram e svd. 
La prima serve per ottenere lo spettrogramma di un segnale audio, che consiste nel suddividere il segnale in intervalli di tempo uguali, finestrarli utilizzando una delle numerose finestre disponibili (nel nostro caso la finestra di Hamming), quindi calcolare la FFT di questi segmenti, utilizzando un numero di campioni a scelta. Da questo procedimento si ottiene perciò una matrice, dove ogni colonna contiene la FFT del segmento di segnale designato (e dunque il numero di righe della matrice equivale al numero di campioni della FFT, mentre il numero di colonne equivale al numero di segmenti in cui è stato suddiviso il segnale).
La seconda funzione, invece, esegue la Decomposizione ai Valori Singolari (SVD, Singular Value Decomposition) su una matrice (m,n) in ingresso M: questa pratica consiste in una fattorizzazione della matrice M in un prodotto tra tre matrici M = U*S*(V'), dove U è una matrice unitaria (ovvero una matrice il cui prodotto con la sua matrice trasposta coniugata dà la matrice unitaria) di dimensioni (m,m), S è una matrice diagonale rettangolare di dimensioni (m,n) e V' è la trasposta coniugata di una matrice unitaria V di dimensioni (n,n). Gli elementi sulla diagonale principale di S sono le radici quadrate degli autovalori associati agli autovettori che si trovano sulle colonne di V.

Per implementare il training abbiamo utilizzato tre diversi metodi.

PRIMO METODO
Innanzitutto abbiamo caricato i file audio di musica e di parlato, quindi abbiamo calcolato lo spettrogramma per ogni file. Come impostazioni per lo spettrogramma abbiamo seguito la documentazione dello standard mpeg7 allegata, paragrafo 1.1.2.3.4. Poichè la frequenza di campionamento dei file è pari a 16000 Hz, abbiamo ottenuto una hopsize (corrispondente al valore noverlap della funzione di Numpy) pari a 160, la lunghezza della finestra pari alla più piccola potenza di 2 maggiore di 3 hopsize, ovvero 512 campioni, che è anche il numero di campioni della FFT. La finestra utilizzata, come da specifiche, è quella di Hamming.
A questo punto abbiamo concatenato tra loro tutti gli spettrogrammi dei file di musica, e poi abbiamo ripetuto la stessa cosa per i file di parlato, in modo da ottenere due classi distinte che rappresentassero le due categorie. Algebricamente parlando, le due classi risultano essere due sottospazi.
Il passo successivo è stato quello di ottenere due basi di vettori che generassero i sottospazi; abbiamo perciò calcolato la SVD dei due spettrogrammi, ricavando dalle colonne della matrice U gli autovettori richiesti, con l'accortezza di non sceglierli tutti, in quanto così facendo avremmo potuto ottenere ricostruzioni perfette di ogni segnale per entrambi i sottospazi, impedendo una classificazione efficace. Al contrario, poichè ad ogni autovettore è associato un autovalore che rappresenta la sua energia, abbiamo selezionato solo i primi autovettori in ordine di energia, affinchè la somma dei loro autovalori fosse pari al 60% del totale.
Una volta ottenute le due basi, abbiamo caricato i 10 file incogniti, e per ognuno di essi abbiamo calcolato lo spettrogramma (con le impostazioni precedenti). Successivamente abbiamo calcolato per ognuno di essi la proiezione dello spettrogramma su entrambi i sottospazi attraverso i prodotti scalari tra le colonne dello spettrogramma e gli autovettori della classe. A questo punto abbiamo calcolato le due matrici errore come la differenza tra la proiezione del file incognito su un sottospazio e lo spettrogramma originale, e ne abbiamo calcolato le norme quadratiche (o di Frobenius); la categoria la cui matrice errore aveva norma minore era quella che meglio rappresentava il segnale incognito.

SECONDO METODO
Per il secondo metodo si procede allo stesso modo del precedente fino ad ottenere le due basi di autovettori per le classi di musica e di parlato.
A questo punto, invece che procedere con la proiezione dei suoni incogniti, si ottiene una 'feature' per ognuna delle due classi: una 'feature' è un elemento che rappresenta in modo sintetico l'intera classe. Per ottenere questa 'feature' abbiamo calcolato il vettore dei coefficienti della proiezione di ognuno dei vettori dello spettrogramma di una classe musica sulla base di autovettori della stessa classe, e poi abbiamo calcolato il vettore medio tra tutti i vettori dei coefficienti. Questi due vettori medi, uno per classe, rappresentano le nostre 'feature' per le due categorie.
Passando quindi ai file incogniti, abbiamo calcolato lo spettrogramma di ognuno, e abbiamo proceduto come con lo spettrogramma delle due classi, calcolandone il vettore medio dei coefficienti. Quindi, per decidere quale categoria è quella corretta, abbiamo calcolato i due vettori errore come differenza tra il vettore medio del file incognito e la 'feature' della classe, e quello che possedeva norma quadratica minore era quello della classe giusta.

TERZO METODO
Per il terzo metodo si procede sulla falsa riga del secondo, ma al contrario di quest'ultimo si utilizza una sola classe che include sia i file di musica che quelli di parlato. In pratica si concatenano gli spettrogrammi delle due categorie calcolati in precedenza, in modo da formare un unico spettrogramma, da cui si ricava la base di autovettori tramite la SVD nello stesso modo con cui la si era ottenuta per le singole classi.
A questo punto, si ottengono le 'feature' delle due categorie calcolando i vettori dei coefficienti della proiezione di ogni file di una delle due categorie sulla classe unica, e calcolandone il vettore medio (come fatto anche nel secondo metodo). Si procede quindi con i file incogniti, calcolandone come prima il vettore medio dei coefficienti della proiezione sulla classe unica. Per decidere quale categoria è quella corretta, si calcolano i due vettori errore come differenza tra il vettore medio del file incognito e la 'feature' della categoria, prediligendo quello che possiede norma quadratica minore.
