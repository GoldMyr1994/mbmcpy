{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <header>\n",
    "        <h1>Audio Classifier Python</h1>\n",
    "        <h2>Marco Bondaschi, Mauro Conte</h2>\n",
    "        <h4>Laboratorio di Telecomunicazioni</h4>\n",
    "        <h5>Università Degli Studi Di Brescia</h5>\n",
    "        <h6>13/03/2017</h6>\n",
    "    </header>\n",
    "</center>\n",
    "<hr><hr>\n",
    "\n",
    "<h2>Descrizione</h2>\n",
    "\n",
    "Per questa prima esperienza di laboratorio, abbiamo realizzato un software di classificazione audio, realizzato in Python, che permettesse di analizzare e distinguere un file musicale da uno di parlato.\n",
    "\n",
    "Per realizzare questo compito abbiamo usufruito di un database di 40 file audio .wav, MONO e con frequenza di campionamento pari a 16000 Hz, già suddivisi in 20 file di musica (dalla durata di 10 s l'uno) e 20 file di parlato (dalla durata di 3 s l'uno).\n",
    "\n",
    "Abbiamo inoltre in dotazione un database di 10 suoni incogniti, sempre MONO a 16000Hz, che il nostro software dovrà essere in grado di dividere in musica o parlato.\n",
    "\n",
    "Il primo passo per creare il software di classificazione è la fase di training, attraverso la quale si addestra il software a distinguere musica e parlato facendogli analizzare i 40 file già suddivisi nelle due categorie.\n",
    "\n",
    "In secondo luogo si attua la fase di test, in cui si consegnano al software i 10 file incogniti, che verranno analizzati dal programma e suddivisi in musica o parlato.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Strumenti</h3>\n",
    "\n",
    "Per raggiungere questi obiettivi, è stato necessario utilizzare le estensioni Scipy e Numpy, che implementano funzioni matematiche di alto livello. In particolare abbiamo utilizzato due funzioni fondamentali: spectrogram e svd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "import scipy.linalg\n",
    "import scipy.io.wavfile\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Spectrogram</h3>\n",
    "La prima serve per ottenere lo spettrogramma di un segnale audio, che consiste nel suddividere il segnale in intervalli di tempo uguali, finestrarli utilizzando una delle numerose finestre disponibili (nel nostro caso la finestra di Hamming), quindi calcolare la FFT di questi segmenti, utilizzando un numero di campioni a scelta. Da questo procedimento si ottiene perciò una matrice, dove ogni colonna contiene la FFT del segmento di segnale designato (e dunque il numero di righe della matrice equivale al numero di campioni della FFT, mentre il numero di colonne equivale al numero di segmenti in cui è stato suddiviso il segnale).\n",
    "\n",
    "<h3>SVD</h3>\n",
    "La seconda funzione, invece, esegue la Decomposizione ai Valori Singolari (SVD, Singular Value Decomposition) su una matrice $M\\in{\\mathbb{C}^{(m,n)}}$\n",
    "\n",
    "Questa pratica consiste in una fattorizzazione della matrice $M$ in un prodotto tra tre matrici $M=USV^{*}$, dove:\n",
    "<ul>\n",
    "    <li>\n",
    "$U\\in{\\mathbb{C}^{(m,n)}}$ è una matrice unitaria (ovvero una matrice il cui prodotto con la sua matrice trasposta coniugata dà la matrice unitaria)\n",
    "    </li>\n",
    "    <li>\n",
    "$S$ è una matrice diagonale  $\\in\\mathbb{C}^{(m,n)}$\n",
    "    </li>\n",
    "    <li>\n",
    "$V^{*}$ è la trasposta coniugata di una matrice unitaria $V\\in{\\mathbb{C}^{(n,n)}}$\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "Gli elementi sulla diagonale principale di $S$ sono le radici quadrate degli autovalori associati agli autovettori che si trovano sulle colonne di $V^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ritorna una lista di tuple contenenti SampleRate, Data, FileName data una path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_audio(path):\n",
    "    audio_list = []\n",
    "    for filename in os.listdir(path):\n",
    "        rate, data = scipy.io.wavfile.read(path + filename) \n",
    "        audio_list.append((rate, data, filename))\n",
    "    return audio_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ritorna lo spettrogramma  di un segnale dati il SampleRate e Data.\n",
    "\n",
    "Come impostazioni per lo spettrogramma abbiamo seguito la documentazione dello standard mpeg7 allegata, paragrafo 1.1.2.3.4. Poichè la frequenza di campionamento dei file è pari a 16000 Hz, abbiamo ottenuto una hopsize (corrispondente al valore noverlap della funzione di Numpy) pari a 160, la lunghezza della finestra pari alla più piccola potenza di 2 maggiore di 3 hopsize, ovvero 512 campioni, che è anche il numero di campioni della FFT. La finestra utilizzata, come da specifiche, è quella di Hamming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spectrogram(data, rate):\n",
    "    f, t, sxx = signal.spectrogram(data, rate, 'hamming', 512, 160, 512)\n",
    "    spectrogram = 10 * np.log10(sxx + sys.float_info.min)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ritorna lo spettrogramma di un insieme di audio data la lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spectrogram_from_list(collection):\n",
    "    spectrogram = None\n",
    "    for rate,data,f_name in collection:\n",
    "        if spectrogram is None: spectrogram = get_spectrogram(data,rate)\n",
    "        else: scipy.hstack((spectrogram, get_spectrogram(data,rate)))\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ritorna una matrice che ha per colonne i vettori di una base ridotta dello spazio vettoriale che genera lo spettrogramma dato lo stesso e la percentuale di energia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_base_from_spectrogram(spectrogram,percent):\n",
    "    u, s, v = np.linalg.svd(spectrogram)\n",
    "    energy_e_value = np.sum(s)\n",
    "    current_sum = 0\n",
    "    percent_sum = energy_e_value * percent / 100\n",
    "    for i in range(len(s)):\n",
    "        current_sum += s[i]\n",
    "        if current_sum >= percent_sum:\n",
    "            break\n",
    "    base = u[:, range(0, i)]\n",
    "    return base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ritorna la feature relativa ad un audio ricavata dal suo spettrogramma e dalla base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_mean(spectrogram, base):\n",
    "    mean_vector = np.zeros(base.shape[1])\n",
    "    coefficient_on_base = np.dot(spectrogram.T, base)\n",
    "    mean_vector += np.mean(coefficient_on_base, 0)\n",
    "    return mean_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ritorna la feature relativa ad una lista di audio ricavata dal suo spettrogramma e dalla base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_mean_from_list(collection, base):\n",
    "    mean_vector = np.zeros(base.shape[1])\n",
    "    for rate, data, filename in collection:\n",
    "        spectrogram = get_spectrogram(data,rate)\n",
    "        mean_vector += get_feature_mean(spectrogram,base)\n",
    "    return mean_vector / len(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcola l'approssimazione dello spettrogramma su una base\n",
    "\n",
    "Ritorna l'errore tra lo spettrogramma originale e l'approssimato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_error_base(spectrogram, base):\n",
    "    coefficient_on_base = np.dot(spectrogram.T, base)\n",
    "    spectrogram_ric = np.dot(coefficient_on_base, base.T).T\n",
    "    error = np.linalg.norm(spectrogram - spectrogram_ric)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_db = os.getcwd()+'/05_AudioClassifier_Pdf/05_AudioClassifier_Pdf/database/'\n",
    "path_music = path_db + 'music/'\n",
    "path_speech = path_db + 'speech/'\n",
    "path_unknowns = path_db.replace('database/', '') + 'unknownSounds/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "music = load_audio(path_music)\n",
    "speech = load_audio(path_speech)\n",
    "unknowns = load_audio(path_unknowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spectrogram_music = get_spectrogram_from_list(music)\n",
    "spectrogram_speech = get_spectrogram_from_list(speech)\n",
    "spectrogram_total = scipy.hstack((spectrogram_music, spectrogram_speech))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "energy = 50\n",
    "base_music = get_base_from_spectrogram(spectrogram_music,energy)\n",
    "base_speech = get_base_from_spectrogram(spectrogram_speech,energy)\n",
    "base_total = get_base_from_spectrogram(spectrogram_total,energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_mean_music = get_feature_mean_from_list(music,base_music)\n",
    "feature_mean_speech = get_feature_mean_from_list(speech,base_speech)\n",
    "feature_mean_music_on_total = get_feature_mean_from_list(music,base_total)\n",
    "feature_mean_speech_on_total = get_feature_mean_from_list(speech,base_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item:  004_BobDylan-OxfordTown-10s-B.wav\n",
      "\tMetodo1::  PARLATO\n",
      "\tMetodo2::  MUSICA\n",
      "\tMetodo3::  MUSICA\n",
      "Item:  007si1079.wav\n",
      "\tMetodo1::  PARLATO\n",
      "\tMetodo2::  PARLATO\n",
      "\tMetodo3::  PARLATO\n",
      "Item:  007si1271.wav\n",
      "\tMetodo1::  PARLATO\n",
      "\tMetodo2::  PARLATO\n",
      "\tMetodo3::  PARLATO\n",
      "Item:  010_CiboMatto-Moonchild-10s-A.wav\n",
      "\tMetodo1::  MUSICA\n",
      "\tMetodo2::  MUSICA\n",
      "\tMetodo3::  MUSICA\n",
      "Item:  014si1291.wav\n",
      "\tMetodo1::  PARLATO\n",
      "\tMetodo2::  PARLATO\n",
      "\tMetodo3::  PARLATO\n",
      "Item:  016si1621.wav\n",
      "\tMetodo1::  PARLATO\n",
      "\tMetodo2::  PARLATO\n",
      "\tMetodo3::  PARLATO\n",
      "Item:  019_Nirvana-Downer-10s-B.wav\n",
      "\tMetodo1::  MUSICA\n",
      "\tMetodo2::  MUSICA\n",
      "\tMetodo3::  MUSICA\n",
      "Item:  024_JimiHendrix-WaitUntilTomorrow-10s-A.wav\n",
      "\tMetodo1::  MUSICA\n",
      "\tMetodo2::  MUSICA\n",
      "\tMetodo3::  MUSICA\n"
     ]
    }
   ],
   "source": [
    "for rate,data,filename in unknowns:\n",
    "    current_spectrogram = get_spectrogram(data , rate)\n",
    "    print('Item: ',filename)\n",
    "    \n",
    "    err_on_speech = get_error_base(current_spectrogram,base_speech)\n",
    "    err_on_music = get_error_base(current_spectrogram,base_music)\n",
    "    print('\\tMetodo1:: ','MUSICA' if err_on_music<err_on_speech else'PARLATO')\n",
    "\n",
    "    err_on_speech = np.linalg.norm(feature_mean_speech-get_feature_mean(current_spectrogram,base_speech))\n",
    "    err_on_music = np.linalg.norm(feature_mean_music-get_feature_mean(current_spectrogram,base_music))\n",
    "    print('\\tMetodo2:: ','MUSICA' if err_on_music<err_on_speech else'PARLATO')\n",
    "    \n",
    "    err_on_speech = np.linalg.norm(feature_mean_speech_on_total-get_feature_mean(current_spectrogram,base_total))\n",
    "    err_on_music = np.linalg.norm(feature_mean_music_on_total-get_feature_mean(current_spectrogram,base_total))\n",
    "    print('\\tMetodo3:: ','MUSICA' if err_on_music<err_on_speech else'PARLATO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
